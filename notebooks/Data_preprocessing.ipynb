{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10391 entries, 0 to 10390\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   schoolid  10391 non-null  int64  \n",
      " 1   Z         10391 non-null  int64  \n",
      " 2   Y         10391 non-null  float64\n",
      " 3   S3        10391 non-null  int64  \n",
      " 4   C1        10391 non-null  int64  \n",
      " 5   C2        10391 non-null  int64  \n",
      " 6   C3        10391 non-null  int64  \n",
      " 7   XC        10391 non-null  int64  \n",
      " 8   X1        10391 non-null  float64\n",
      " 9   X2        10391 non-null  float64\n",
      " 10  X3        10391 non-null  float64\n",
      " 11  X4        10391 non-null  float64\n",
      " 12  X5        10391 non-null  float64\n",
      "dtypes: float64(6), int64(7)\n",
      "memory usage: 1.0 MB\n",
      "None\n",
      "Dataset Description:\n",
      "           schoolid             Z             Y            S3            C1  \\\n",
      "count  10391.000000  10391.000000  10391.000000  10391.000000  10391.000000   \n",
      "mean      39.888846      0.325666     -0.096742      5.268117      5.223078   \n",
      "std       24.008975      0.468646      0.643009      1.120765      3.982963   \n",
      "min        1.000000      0.000000     -2.097420      1.000000      1.000000   \n",
      "25%       19.000000      0.000000     -0.548980      5.000000      3.000000   \n",
      "50%       41.000000      0.000000     -0.118923      5.000000      4.000000   \n",
      "75%       62.000000      1.000000      0.335663      6.000000      5.000000   \n",
      "max       76.000000      1.000000      2.194709      7.000000     15.000000   \n",
      "\n",
      "                 C2            C3            XC            X1            X2  \\\n",
      "count  10391.000000  10391.000000  10391.000000  10391.000000  10391.000000   \n",
      "mean       1.489943      0.630931      2.447791     -0.040457      0.054841   \n",
      "std        0.499923      0.482576      1.378420      0.969743      0.935560   \n",
      "min        1.000000      0.000000      0.000000     -3.088790     -3.347819   \n",
      "25%        1.000000      0.000000      1.000000     -0.617888     -0.544506   \n",
      "50%        1.000000      1.000000      2.000000     -0.009954     -0.022514   \n",
      "75%        2.000000      1.000000      4.000000      0.420441      0.726836   \n",
      "max        2.000000      1.000000      4.000000      2.834589      2.171815   \n",
      "\n",
      "                 X3            X4            X5  \n",
      "count  10391.000000  10391.000000  10391.000000  \n",
      "mean      -0.089349     -0.045911     -0.026168  \n",
      "std        0.962804      0.967262      1.010387  \n",
      "min       -1.575463     -1.924778     -1.805073  \n",
      "25%       -0.963095     -0.813799     -0.857026  \n",
      "50%       -0.057036     -0.159602     -0.211553  \n",
      "75%        0.515392      0.596474      0.847844  \n",
      "max        2.358274      2.821660      1.892348  \n",
      "Transformed Training Set:\n",
      "         X1        X2        X3        X4        X5  \\\n",
      "0 -0.510445  1.466730  0.051898 -0.967223  1.590097   \n",
      "1  0.384140  0.629177 -1.277115  0.276209 -0.402070   \n",
      "2 -0.321221  1.286003 -0.766009 -1.148723  0.818729   \n",
      "3  0.031335  0.751005 -0.148416  0.130397  0.365255   \n",
      "4 -0.510445  1.466730  0.051898 -0.967223  1.590097   \n",
      "\n",
      "   Mindset_School_Achievement_Interaction  C1_2  C1_3  C1_4  C1_5  ...  C1_12  \\\n",
      "0                               -0.226342   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "1                                0.702910   0.0   0.0   1.0   0.0  ...    0.0   \n",
      "2                                0.078730   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "3                                0.492070   0.0   0.0   1.0   0.0  ...    0.0   \n",
      "4                               -0.226342   0.0   0.0   1.0   0.0  ...    0.0   \n",
      "\n",
      "   C1_13  C1_14  C1_15  C2_2  C3_1  XC_1  XC_2  XC_3  XC_4  \n",
      "0    0.0    0.0    0.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
      "1    0.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   1.0  \n",
      "2    0.0    0.0    0.0   0.0   1.0   0.0   1.0   0.0   0.0  \n",
      "3    0.0    0.0    0.0   0.0   1.0   0.0   1.0   0.0   0.0  \n",
      "4    0.0    0.0    0.0   1.0   1.0   1.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Transformed Test Set:\n",
      "         X1        X2        X3        X4        X5  \\\n",
      "0  1.057072 -0.781669  1.713448  0.283093 -1.473120   \n",
      "1 -0.014951 -0.643397  1.441220 -1.743257 -0.762711   \n",
      "2  1.650047 -1.152172  0.462079  1.121334 -0.445150   \n",
      "3 -1.227630  0.576547  0.092037  1.351892  0.965193   \n",
      "4  1.049241 -0.542535  0.178085 -0.632087 -0.300609   \n",
      "\n",
      "   Mindset_School_Achievement_Interaction  C1_2  C1_3  C1_4  C1_5  ...  C1_12  \\\n",
      "0                               -0.128421   1.0   0.0   0.0   0.0  ...    0.0   \n",
      "1                                0.527391   1.0   0.0   0.0   0.0  ...    0.0   \n",
      "2                               -1.007105   0.0   0.0   1.0   0.0  ...    0.0   \n",
      "3                               -0.198014   0.0   0.0   0.0   1.0  ...    0.0   \n",
      "4                                0.083536   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "\n",
      "   C1_13  C1_14  C1_15  C2_2  C3_1  XC_1  XC_2  XC_3  XC_4  \n",
      "0    0.0    0.0    0.0   0.0   1.0   0.0   0.0   1.0   0.0  \n",
      "1    0.0    0.0    0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
      "2    0.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   1.0  \n",
      "3    0.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   1.0  \n",
      "4    0.0    0.0    0.0   1.0   1.0   0.0   0.0   0.0   1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Training data shape: (8312, 26), Test data shape: (2079, 26)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('../data/dataset.csv')\n",
    "\n",
    "\n",
    "# Display basic info of the dataset to check for missing values and data types\n",
    "print(\"Dataset Information:\")\n",
    "print(dataset.info())\n",
    "print(\"Dataset Description:\")\n",
    "print(dataset.describe())\n",
    "\n",
    "# Step 1: Feature Engineering (optional, you can add more interactions based on domain knowledge)\n",
    "# Example: Creating an interaction feature between mindset and school achievement level\n",
    "dataset['Mindset_School_Achievement_Interaction'] = dataset['X1'] * dataset['X2']\n",
    "\n",
    "# Step 2: Define covariates (features), treatment, and outcome\n",
    "outcome_col = 'Y'  # Student Achievement Score (Outcome)\n",
    "treatment_col = 'Z'  # Growth Mindset Intervention (Treatment)\n",
    "covariate_cols = ['S3', 'C1', 'C2', 'C3', 'XC', 'X1', 'X2', 'X3', 'X4', 'X5', 'Mindset_School_Achievement_Interaction']\n",
    "\n",
    "# Step 3: Categorical and Numerical Feature Identification\n",
    "# Categorical columns that need one-hot encoding\n",
    "categorical_cols = ['C1', 'C2', 'C3', 'XC']\n",
    "\n",
    "# Numerical columns that need to be standardized\n",
    "numerical_cols = ['X1', 'X2', 'X3', 'X4', 'X5', 'Mindset_School_Achievement_Interaction']\n",
    "\n",
    "# Step 4: Preprocessing Pipeline\n",
    "# A pipeline that will scale numerical features and one-hot encode categorical ones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),  # Scaling numerical columns\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)  # One-hot encoding categorical columns\n",
    "    ])\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "X = dataset[covariate_cols]  # Features (covariates)\n",
    "y = dataset[outcome_col]  # Outcome (Student Achievement Score)\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Apply the Preprocessing Pipeline\n",
    "# Fit the preprocessor on the training data and transform both train and test sets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Retrieve the feature names after one-hot encoding and scaling\n",
    "# This ensures that our transformed data has the correct column names\n",
    "feature_names = numerical_cols + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Convert the transformed data back to DataFrames for easier use\n",
    "X_train_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "\n",
    "# Step 7: Output the results to verify the transformations\n",
    "print(\"Transformed Training Set:\")\n",
    "print(X_train_df.head())\n",
    "print(\"\\nTransformed Test Set:\")\n",
    "print(X_test_df.head())\n",
    "\n",
    "# Output the shapes of the datasets\n",
    "print(f\"\\nTraining data shape: {X_train_df.shape}, Test data shape: {X_test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Learner MSE: 0.45278502287687317\n",
      "Estimated treatment effects (S-Learner):\n",
      " [0. 0. 0. 0. 0.]\n",
      "Treatment Distribution in Training Set:\n",
      "Z\n",
      "0    5601\n",
      "1    2711\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to handle missing values and train the S-Learner\n",
    "def s_learner(X_train, X_test, y_train, y_test, treatment_train, treatment_test,s_model):\n",
    "    # Append treatment column to training and test sets\n",
    "    X_train_with_treatment = X_train.copy()\n",
    "    X_test_with_treatment = X_test.copy()\n",
    "    \n",
    "    # Add treatment indicator to the feature set\n",
    "    X_train_with_treatment['treatment'] = treatment_train\n",
    "    X_test_with_treatment['treatment'] = treatment_test\n",
    "    \n",
    "    # Handle missing values by imputing them\n",
    "    imputer = SimpleImputer(strategy='mean')  # For numerical values\n",
    "    X_train_imputed = imputer.fit_transform(X_train_with_treatment)\n",
    "    X_test_imputed = imputer.transform(X_test_with_treatment)\n",
    "    \n",
    "    # Use a RandomForestRegressor as the base model for the S-learner\n",
    "    #s_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Train the model on the combined feature set (covariates + treatment indicator)\n",
    "    s_model.fit(X_train_imputed, y_train)\n",
    "    \n",
    "    # Predict outcomes for both treated and untreated cases\n",
    "    X_test_with_treatment['treatment'] = 1  # Treated case\n",
    "    y_pred_treated = s_model.predict(X_test_imputed)\n",
    "    \n",
    "    X_test_with_treatment['treatment'] = 0  # Untreated case\n",
    "    y_pred_control = s_model.predict(X_test_imputed)\n",
    "    \n",
    "    # Calculate the treatment effect (difference between treated and control)\n",
    "    treatment_effect = y_pred_treated - y_pred_control\n",
    "    \n",
    "    # Evaluate the model performance using mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, s_model.predict(X_test_imputed))\n",
    "    print(f\"S-Learner MSE: {mse}\")\n",
    "    \n",
    "    return treatment_effect, s_model\n",
    "\n",
    "# Extract treatment column (Z) for both training and testing datasets\n",
    "treatment_train = dataset.loc[X_train.index, 'Z']\n",
    "treatment_test = dataset.loc[X_test.index, 'Z']\n",
    "\n",
    " # Use a RandomForestRegressor as the base model for the S-learner\n",
    "s_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate the S-learner with missing value handling\n",
    "s_treatment_effect, s_model = s_learner(X_train_df, X_test_df, y_train, y_test, treatment_train, treatment_test,s_model)\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (S-Learner):\\n\", s_treatment_effect[:5])  # Showing first 5 treatment effects\n",
    "print(\"Treatment Distribution in Training Set:\")\n",
    "print(treatment_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Learner MSE: 0.520193741079241\n",
      "Estimated treatment effects (S-Learner, Balanced):\n",
      " [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Combine training data with treatment indicator and target\n",
    "X_train_with_treatment = X_train_df.copy()\n",
    "X_train_with_treatment['Z'] = treatment_train\n",
    "X_train_with_treatment['Y'] = y_train  # Add the target to the dataset\n",
    "\n",
    "# Split treated and untreated groups\n",
    "treated = X_train_with_treatment[X_train_with_treatment['Z'] == 1]\n",
    "untreated = X_train_with_treatment[X_train_with_treatment['Z'] == 0]\n",
    "\n",
    "# Oversample treated group to match the size of the untreated group\n",
    "treated_oversampled = resample(treated, \n",
    "                               replace=True,  # Sample with replacement\n",
    "                               n_samples=len(untreated),  # Match untreated sample size\n",
    "                               random_state=42)\n",
    "\n",
    "# Combine the oversampled treated group with the untreated group\n",
    "balanced_train = pd.concat([untreated, treated_oversampled])\n",
    "\n",
    "# Separate the features, treatment labels, and target again\n",
    "X_train_balanced = balanced_train.drop(columns=['Z', 'Y'])  # Features\n",
    "treatment_train_balanced = balanced_train['Z']  # Treatment indicator\n",
    "y_train_balanced = balanced_train['Y']  # Target (Outcome)\n",
    "\n",
    " # Use a RandomForestRegressor as the base model for the S-learner\n",
    "s_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Now train the S-learner on the balanced dataset\n",
    "s_treatment_effect_balanced, s_model_balanced = s_learner(X_train_balanced, X_test_df, y_train_balanced, y_test, treatment_train_balanced, treatment_test,s_model)\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (S-Learner, Balanced):\\n\", s_treatment_effect_balanced[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treated Model MSE: 0.47066167057112024\n",
      "Control Model MSE: 0.44565126147139134\n",
      "Estimated treatment effects (T-Learner):\n",
      " [0.11595774 0.43627006 0.13755668 1.16536816 0.6950525 ]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to train and evaluate a T-Learner with aligned indices\n",
    "def t_learner(X_train, X_test, y_train, y_test, treatment_train, treatment_test):\n",
    "    # Reset indices to ensure alignment\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    treatment_train = treatment_train.reset_index(drop=True)\n",
    "    \n",
    "    # Split the training set into treated and control groups\n",
    "    X_train_treated = X_train[treatment_train == 1]\n",
    "    y_train_treated = y_train[treatment_train == 1]\n",
    "    \n",
    "    X_train_control = X_train[treatment_train == 0]\n",
    "    y_train_control = y_train[treatment_train == 0]\n",
    "    \n",
    "    # Use a RandomForestRegressor as the base model for both treated and control groups\n",
    "    treated_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    control_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Train models separately for treated and control groups\n",
    "    treated_model.fit(X_train_treated, y_train_treated)\n",
    "    control_model.fit(X_train_control, y_train_control)\n",
    "    \n",
    "    # Predict outcomes for the test set using both models\n",
    "    y_pred_treated = treated_model.predict(X_test)  # Treated model predictions\n",
    "    y_pred_control = control_model.predict(X_test)  # Control model predictions\n",
    "    \n",
    "    # Calculate the treatment effect (difference between treated and control predictions)\n",
    "    treatment_effect = y_pred_treated - y_pred_control\n",
    "    \n",
    "    # Evaluate the models using MSE\n",
    "    mse_treated = mean_squared_error(y_test, y_pred_treated)\n",
    "    mse_control = mean_squared_error(y_test, y_pred_control)\n",
    "    \n",
    "    print(f\"Treated Model MSE: {mse_treated}\")\n",
    "    print(f\"Control Model MSE: {mse_control}\")\n",
    "    \n",
    "    return treatment_effect, treated_model, control_model\n",
    "\n",
    "# Ensure the treatment column for training and test sets has matching indices with features\n",
    "treatment_train_aligned = treatment_train.reset_index(drop=True)\n",
    "treatment_test_aligned = treatment_test.reset_index(drop=True)\n",
    "\n",
    "# Train and evaluate the T-Learner\n",
    "t_treatment_effect, treated_model, control_model = t_learner(X_train_df, X_test_df, y_train, y_test, treatment_train_aligned, treatment_test_aligned)\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (T-Learner):\\n\", t_treatment_effect[:5])  # Showing first 5 treatment effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Treated Model (T-Learner): 0.47066167057112024\n",
      "MSE for Control Model (T-Learner): 0.44565126147139134\n",
      "MSE for Pseudo-Outcome Model (Treated): 0.22266443542350878\n",
      "MSE for Pseudo-Outcome Model (Control): 0.25023735008863246\n",
      "Estimated treatment effects (X-Learner):\n",
      " [0.11595774 0.43627006 0.13755668 1.15091238 0.7525621 ]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to train and evaluate an X-Learner with MSE evaluation\n",
    "def x_learner(X_train, X_test, y_train, y_test, treatment_train, treatment_test):\n",
    "    # Step 1: Train T-Learner models (treated and control)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    treatment_train = treatment_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_treated = X_train[treatment_train == 1]\n",
    "    y_train_treated = y_train[treatment_train == 1]\n",
    "    \n",
    "    X_train_control = X_train[treatment_train == 0]\n",
    "    y_train_control = y_train[treatment_train == 0]\n",
    "    \n",
    "    treated_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    control_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    treated_model.fit(X_train_treated, y_train_treated)\n",
    "    control_model.fit(X_train_control, y_train_control)\n",
    "    \n",
    "    # Step 1 MSE: Evaluate T-Learner models\n",
    "    y_pred_treated = treated_model.predict(X_test)\n",
    "    y_pred_control = control_model.predict(X_test)\n",
    "    mse_treated = mean_squared_error(y_test, y_pred_treated)\n",
    "    mse_control = mean_squared_error(y_test, y_pred_control)\n",
    "    print(f\"MSE for Treated Model (T-Learner): {mse_treated}\")\n",
    "    print(f\"MSE for Control Model (T-Learner): {mse_control}\")\n",
    "    \n",
    "    # Step 2: Impute outcomes for the opposite group\n",
    "    y_imputed_control_for_treated = control_model.predict(X_train_treated)  # Impute control outcomes for treated group\n",
    "    y_imputed_treated_for_control = treated_model.predict(X_train_control)  # Impute treated outcomes for control group\n",
    "    \n",
    "    # Step 3: Calculate imputed treatment effects (pseudo-outcomes)\n",
    "    pseudo_outcome_treated = y_train_treated - y_imputed_control_for_treated\n",
    "    pseudo_outcome_control = y_imputed_treated_for_control - y_train_control\n",
    "    \n",
    "    # Step 4: Train final models on pseudo-outcomes\n",
    "    final_treated_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    final_control_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    final_treated_model.fit(X_train_treated, pseudo_outcome_treated)\n",
    "    final_control_model.fit(X_train_control, pseudo_outcome_control)\n",
    "    \n",
    "    # Step 4 MSE: Evaluate pseudo-outcome models\n",
    "    pseudo_pred_treated = final_treated_model.predict(X_train_treated)\n",
    "    pseudo_pred_control = final_control_model.predict(X_train_control)\n",
    "    mse_pseudo_treated = mean_squared_error(pseudo_outcome_treated, pseudo_pred_treated)\n",
    "    mse_pseudo_control = mean_squared_error(pseudo_outcome_control, pseudo_pred_control)\n",
    "    print(f\"MSE for Pseudo-Outcome Model (Treated): {mse_pseudo_treated}\")\n",
    "    print(f\"MSE for Pseudo-Outcome Model (Control): {mse_pseudo_control}\")\n",
    "    \n",
    "    # Step 5: Predict treatment effects for the test set\n",
    "    treatment_effect_treated = final_treated_model.predict(X_test)  # Final model predictions for treated pseudo-outcome\n",
    "    treatment_effect_control = final_control_model.predict(X_test)  # Final model predictions for control pseudo-outcome\n",
    "    \n",
    "    # Average the two treatment effects to get the final treatment effect estimate\n",
    "    treatment_effect_xlearner = 0.5 * (treatment_effect_treated + treatment_effect_control)\n",
    "    \n",
    "    return treatment_effect_xlearner, final_treated_model, final_control_model\n",
    "\n",
    "# Train and evaluate the X-Learner with MSE calculations\n",
    "x_treatment_effect, final_treated_model, final_control_model = x_learner(X_train_df, X_test_df, y_train, y_test, treatment_train, treatment_test)\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (X-Learner):\\n\", x_treatment_effect[:5])  # Showing first 5 treatment effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Treated Outcome Model: 0.21964892203290864\n",
      "MSE for Control Outcome Model: 0.24975125763615935\n",
      "MSE for Treatment Effect Model: 0.45872479128868987\n",
      "Estimated treatment effects (R-Learner):\n",
      " [ 0.01418077  0.0112741  -0.01358998 -0.12883522 -0.02388825]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to train and evaluate an R-Learner with MSE evaluation\n",
    "def r_learner(X_train, X_test, y_train, y_test, treatment_train, treatment_test):\n",
    "    # Ensure the indices of X_train, y_train, and treatment_train are aligned\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    treatment_train = treatment_train.reset_index(drop=True)\n",
    "    \n",
    "    # Step 1: Estimate Propensity Scores (Logistic Regression for binary treatment)\n",
    "    propensity_model = LogisticRegression(random_state=42)\n",
    "    propensity_model.fit(X_train, treatment_train)\n",
    "    propensity_scores = propensity_model.predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    # Step 2: Estimate Outcome Models (treated and control)\n",
    "    outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    outcome_model_control = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Train models on treated and control groups\n",
    "    outcome_model_treated.fit(X_train[treatment_train == 1], y_train[treatment_train == 1])\n",
    "    outcome_model_control.fit(X_train[treatment_train == 0], y_train[treatment_train == 0])\n",
    "    \n",
    "    # Predict outcomes for both treated and control cases\n",
    "    y_pred_treated = outcome_model_treated.predict(X_train)\n",
    "    y_pred_control = outcome_model_control.predict(X_train)\n",
    "    \n",
    "    # Step 2 MSE: Evaluate Outcome Models\n",
    "    mse_treated = mean_squared_error(y_train[treatment_train == 1], y_pred_treated[treatment_train == 1])\n",
    "    mse_control = mean_squared_error(y_train[treatment_train == 0], y_pred_control[treatment_train == 0])\n",
    "    print(f\"MSE for Treated Outcome Model: {mse_treated}\")\n",
    "    print(f\"MSE for Control Outcome Model: {mse_control}\")\n",
    "    \n",
    "    # Step 3: Calculate Residuals\n",
    "    residuals_treated = (y_train - y_pred_treated) / propensity_scores\n",
    "    residuals_control = (y_train - y_pred_control) / (1 - propensity_scores)\n",
    "    \n",
    "    # Step 4: Fit final treatment effect model (RandomForest)\n",
    "    treatment_effect_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    treatment_effect_model.fit(X_train, treatment_train * residuals_treated + (1 - treatment_train) * residuals_control)\n",
    "    \n",
    "    # Predict treatment effects for the test set\n",
    "    treatment_effect_test = treatment_effect_model.predict(X_test)\n",
    "    \n",
    "    # Step 4 MSE: Evaluate Treatment Effect Model\n",
    "    mse_treatment_effect = mean_squared_error(y_test, treatment_effect_test)\n",
    "    print(f\"MSE for Treatment Effect Model: {mse_treatment_effect}\")\n",
    "    \n",
    "    return treatment_effect_test, treatment_effect_model\n",
    "\n",
    "# Ensure the treatment column for training and test sets has matching indices with features\n",
    "treatment_train_aligned = treatment_train.reset_index(drop=True)\n",
    "treatment_test_aligned = treatment_test.reset_index(drop=True)\n",
    "\n",
    "# Train and evaluate the R-Learner with MSE calculations\n",
    "r_treatment_effect, r_model = r_learner(X_train_df, X_test_df, y_train, y_test, treatment_train_aligned, treatment_test_aligned)\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (R-Learner):\\n\", r_treatment_effect[:5])  # Showing first 5 treatment effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for S-Learner (Gradient Boosting): {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "S-Learner MSE: 0.3777395615180631\n",
      "Estimated treatment effects (S-Learner, Tuned):\n",
      " [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Fine-tuning the S-Learner using Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Use Gradient Boosting Regressor for the S-Learner\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Handle missing values for grid search\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_df.join(treatment_train))\n",
    "\n",
    "# Use GridSearchCV to find the best parameters for Gradient Boosting\n",
    "grid_search = GridSearchCV(gbm, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Get the best parameters and the tuned model\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters for S-Learner (Gradient Boosting):\", best_params)\n",
    "\n",
    "# Pass the tuned model to the S-Learner\n",
    "tuned_model = GradientBoostingRegressor(**best_params, random_state=42)\n",
    "s_treatment_effect, s_model = s_learner(X_train_df, X_test_df, y_train, y_test, treatment_train, treatment_test, tuned_model)\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (S-Learner, Tuned):\\n\", s_treatment_effect[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment Distribution in Training Set:\n",
      "Z\n",
      "0    5601\n",
      "1    2711\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Treatment Distribution in Training Set:\")\n",
    "print(treatment_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Learner MSE: 0.2687659747632729\n",
      "Estimated treatment effects (S-Learner, with interaction terms):\n",
      " [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'X1' with an actual feature name in your dataset\n",
    "X_train_interaction = X_train.copy()\n",
    "X_train_interaction['treatment_interaction'] = X_train['X1'] * treatment_train  # Interact X1 with treatment\n",
    "\n",
    "X_test_interaction = X_test.copy()\n",
    "X_test_interaction['treatment_interaction'] = X_test['X1'] * treatment_test  # Same for test set\n",
    "\n",
    "# Use this new feature set for model training\n",
    "s_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "s_treatment_effect, s_model = s_learner(X_train_interaction, X_test_interaction, y_train, y_test, treatment_train, treatment_test, s_model)\n",
    "\n",
    "# Print the treatment effects\n",
    "print(\"Estimated treatment effects (S-Learner, with interaction terms):\\n\", s_treatment_effect[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Learner MSE: 0.45278502287687317\n",
      "Estimated treatment effects (S-Learner, Random Forest):\n",
      " [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Use RandomForestRegressor instead of Gradient Boosting\n",
    "s_model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "s_treatment_effect_rf, s_model_rf = s_learner(X_train_df, X_test_df, y_train, y_test, treatment_train, treatment_test, s_model_rf)\n",
    "\n",
    "# Print the estimated treatment effects using Random Forest\n",
    "print(\"Estimated treatment effects (S-Learner, Random Forest):\\n\", s_treatment_effect_rf[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE Scores: [0.36535378 0.37363385 0.35033632 0.34084314 0.37415565]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Handle missing values by imputing them\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace missing values with the column mean\n",
    "X_train_imputed = imputer.fit_transform(X_train_df.join(treatment_train))  # Impute training data\n",
    "\n",
    "# Use Gradient Boosting Regressor as the base model for the S-learner (without GridSearch)\n",
    "s_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Use cross-validation to check model performance across multiple folds\n",
    "cv_scores = cross_val_score(s_model, X_train_imputed, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Print the Cross-Validation MSE Scores\n",
    "print(\"Cross-Validation MSE Scores:\", -cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Learner MSE: 0.3864978186060779\n",
      "Estimated treatment effects (S-Learner, Polynomial Features):\n",
      " [0.16798218 0.16823798 0.35765285 0.43156245 0.28123992]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Estimate propensity scores using Logistic Regression\n",
    "propensity_model = LogisticRegression(random_state=42)\n",
    "propensity_model.fit(X_train_df, treatment_train)\n",
    "\n",
    "# Get propensity scores for training and test sets\n",
    "propensity_scores_train = propensity_model.predict_proba(X_train_df)[:, 1]\n",
    "propensity_scores_test = propensity_model.predict_proba(X_test_df)[:, 1]\n",
    "\n",
    "# Step 2: Add propensity scores to the training and test datasets\n",
    "X_train_with_ps = X_train_df.copy()\n",
    "X_train_with_ps['propensity_score'] = propensity_scores_train\n",
    "\n",
    "X_test_with_ps = X_test_df.copy()\n",
    "X_test_with_ps['propensity_score'] = propensity_scores_test\n",
    "\n",
    "# Step 3: Handle missing values by imputing them\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_with_ps)\n",
    "X_test_imputed = imputer.transform(X_test_with_ps)\n",
    "\n",
    "# Step 4: Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_imputed)\n",
    "X_test_poly = poly.transform(X_test_imputed)\n",
    "\n",
    "# Step 5: Add treatment column to the imputed and polynomial features using np.column_stack\n",
    "X_train_poly_with_treatment = np.column_stack((X_train_poly, treatment_train.values))  # Convert treatment to numpy array if needed\n",
    "X_test_poly_with_treatment = np.column_stack((X_test_poly, treatment_test.values))  # Same for test set\n",
    "\n",
    "# Step 6: Train the S-Learner using Gradient Boosting\n",
    "s_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "s_model.fit(X_train_poly_with_treatment, y_train)\n",
    "\n",
    "# Predict outcomes for both treated and untreated cases\n",
    "X_test_poly_with_treatment[:, -1] = 1  # For treated cases\n",
    "y_pred_treated = s_model.predict(X_test_poly_with_treatment)\n",
    "\n",
    "X_test_poly_with_treatment[:, -1] = 0  # For untreated cases\n",
    "y_pred_control = s_model.predict(X_test_poly_with_treatment)\n",
    "\n",
    "# Calculate the treatment effect\n",
    "treatment_effect = y_pred_treated - y_pred_control\n",
    "\n",
    "# Step 7: Evaluate the model performance using mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, s_model.predict(X_test_poly_with_treatment))\n",
    "print(f\"S-Learner MSE: {mse}\")\n",
    "\n",
    "# Print the estimated treatment effects\n",
    "print(\"Estimated treatment effects (S-Learner, Polynomial Features):\\n\", treatment_effect[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fine-Tune the Models Further\n",
    "Youâ€™ve used models like Random Forests and Gradient Boosting. Consider:\n",
    "Hyperparameter tuning (as you did with grid search).\n",
    "Trying more advanced models (e.g., neural networks, causal forests) to see if they improve CATE estimation.\n",
    "Exploring cross-validation further to check model performance stability across different data splits.\n",
    "2. Deeper Analysis of Heterogeneity\n",
    "Look at how CATE varies by different covariates. For example, does the treatment work better for certain subgroups (e.g., students with high prior achievement vs. low prior achievement)?\n",
    "Use interaction terms in your models (e.g., interacting covariates with the treatment) to uncover deeper insights into how different factors influence the treatment effect.\n",
    "3. Sensitivity Analysis\n",
    "Test the robustness of your CATE estimates by performing sensitivity analyses. For instance, assess how the results change when you alter the covariates or use different sample sizes.\n",
    "4. Policy Recommendations\n",
    "Based on the results, you can make data-driven recommendations about the effectiveness of the treatment. If certain subgroups benefit more, it may inform targeted interventions or personalized treatments.\n",
    "5. Explore Causal Inference Extensions\n",
    "You could apply other causal inference methods, such as instrumental variables or causal forests, for further validation of your findings. These methods can offer different perspectives on estimating treatment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
