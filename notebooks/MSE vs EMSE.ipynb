{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "MSE with K-Fold Cross-Validation\n",
    "1. Process:\n",
    "\n",
    "K-Fold Cross-Validation is a technique where the dataset is split into\n",
    "𝐾\n",
    "K equally sized (or nearly equal) subsets, called folds.\n",
    "The model is trained\n",
    "𝐾\n",
    "K times, each time using\n",
    "𝐾\n",
    "−\n",
    "1\n",
    "K−1 folds as the training set and the remaining 1 fold as the validation set.\n",
    "The MSE is computed for each fold, and the average MSE across all folds is reported as the final estimate of model performance.\n",
    "2. Formula: If we denote the MSE for the\n",
    "𝑘\n",
    "k-th fold as\n",
    "MSE\n",
    "𝑘\n",
    "MSE\n",
    "k\n",
    "​\n",
    " , then the average MSE over\n",
    "𝐾\n",
    "K folds is:\n",
    "\n",
    "MSE\n",
    "K-Fold\n",
    "=\n",
    "1\n",
    "𝐾\n",
    "∑\n",
    "𝑘\n",
    "=\n",
    "1\n",
    "𝐾\n",
    "MSE\n",
    "𝑘\n",
    "MSE\n",
    "K-Fold\n",
    "​\n",
    " =\n",
    "K\n",
    "1\n",
    "​\n",
    "\n",
    "k=1\n",
    "∑\n",
    "K\n",
    "​\n",
    " MSE\n",
    "k\n",
    "​\n",
    "\n",
    "Where:\n",
    "\n",
    "MSE\n",
    "𝑘\n",
    "=\n",
    "1\n",
    "𝑛\n",
    "𝑘\n",
    "∑\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "𝑛\n",
    "𝑘\n",
    "(\n",
    "𝑦\n",
    "𝑖\n",
    "(\n",
    "𝑘\n",
    ")\n",
    "−\n",
    "𝑦\n",
    "^\n",
    "𝑖\n",
    "(\n",
    "𝑘\n",
    ")\n",
    ")\n",
    "2\n",
    "MSE\n",
    "k\n",
    "​\n",
    " =\n",
    "n\n",
    "k\n",
    "​\n",
    "\n",
    "1\n",
    "​\n",
    " ∑\n",
    "i=1\n",
    "n\n",
    "k\n",
    "​\n",
    "\n",
    "​\n",
    " (y\n",
    "i\n",
    "(k)\n",
    "​\n",
    " −\n",
    "y\n",
    "^\n",
    "​\n",
    "\n",
    "i\n",
    "(k)\n",
    "​\n",
    " )\n",
    "2\n",
    "  is the MSE for the\n",
    "𝑘\n",
    "k-th fold.\n",
    "3. Purpose:\n",
    "\n",
    "The goal is to assess the model's performance across different portions of the dataset, ensuring that the performance estimate is not biased by a particular train-test split.\n",
    "It gives a good estimate of how the model will perform on unseen data, but it is limited to the specific dataset being split into\n",
    "𝐾\n",
    "K folds.\n",
    "EMSE with Bootstrapping\n",
    "1. Process:\n",
    "\n",
    "Bootstrapping involves repeatedly resampling the original dataset with replacement to create many new datasets, known as bootstrap samples.\n",
    "For each bootstrap sample, the model is trained, and the MSE is calculated on the same sample.\n",
    "The average of these MSEs over all bootstrap samples gives the EMSE.\n",
    "2. Formula: If we denote the MSE for the\n",
    "𝑏\n",
    "b-th bootstrap sample as\n",
    "MSE\n",
    "𝑏\n",
    "MSE\n",
    "b\n",
    "​\n",
    " , then the EMSE is calculated as:\n",
    "\n",
    "EMSE\n",
    "=\n",
    "1\n",
    "𝐵\n",
    "∑\n",
    "𝑏\n",
    "=\n",
    "1\n",
    "𝐵\n",
    "MSE\n",
    "𝑏\n",
    "EMSE=\n",
    "B\n",
    "1\n",
    "​\n",
    "\n",
    "b=1\n",
    "∑\n",
    "B\n",
    "​\n",
    " MSE\n",
    "b\n",
    "​\n",
    "\n",
    "Where:\n",
    "\n",
    "𝐵\n",
    "B is the total number of bootstrap samples.\n",
    "MSE\n",
    "𝑏\n",
    "=\n",
    "1\n",
    "𝑛\n",
    "𝑏\n",
    "∑\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "𝑛\n",
    "𝑏\n",
    "(\n",
    "𝑦\n",
    "𝑖\n",
    "(\n",
    "𝑏\n",
    ")\n",
    "−\n",
    "𝑦\n",
    "^\n",
    "𝑖\n",
    "(\n",
    "𝑏\n",
    ")\n",
    ")\n",
    "2\n",
    "MSE\n",
    "b\n",
    "​\n",
    " =\n",
    "n\n",
    "b\n",
    "​\n",
    "\n",
    "1\n",
    "​\n",
    " ∑\n",
    "i=1\n",
    "n\n",
    "b\n",
    "​\n",
    "\n",
    "​\n",
    " (y\n",
    "i\n",
    "(b)\n",
    "​\n",
    " −\n",
    "y\n",
    "^\n",
    "​\n",
    "\n",
    "i\n",
    "(b)\n",
    "​\n",
    " )\n",
    "2\n",
    "  is the MSE for the\n",
    "𝑏\n",
    "b-th bootstrap sample.\n",
    "3. Purpose:\n",
    "\n",
    "The goal is to estimate how the model performs on different possible datasets that could be drawn from the underlying population.\n",
    "By averaging MSEs across different resampled datasets, EMSE accounts for the variability in the data and provides a more robust estimate of the model’s generalization error.\n",
    "Key Differences\n",
    "Data Resampling:\n",
    "\n",
    "K-Fold Cross-Validation: Uses all data in each fold but partitions it into training and validation sets without replacement. Each data point is used exactly once as part of a validation set.\n",
    "Bootstrapping (EMSE): Resamples the dataset with replacement, meaning some data points might appear multiple times in a bootstrap sample, while others might not appear at all.\n",
    "Estimate of Performance:\n",
    "\n",
    "MSE with K-Fold: Provides an average MSE across different splits of the data, giving a reliable estimate of model performance for that specific dataset.\n",
    "EMSE with Bootstrapping: Provides an average MSE across different bootstrap samples, simulating the process of drawing multiple datasets from the population. This offers a more generalized estimate of performance that accounts for the variability in the data.\n",
    "Bias and Variance:\n",
    "\n",
    "K-Fold Cross-Validation: Typically provides a lower variance estimate of performance since it uses all data points in training and validation across different folds. However, it might be slightly biased depending on the folds' composition.\n",
    "Bootstrapping: Can reduce bias and better capture the variance in the model’s performance, providing a more realistic view of how the model might perform on unseen data drawn from the same distribution.\n",
    "Computational Complexity:\n",
    "\n",
    "K-Fold Cross-Validation: Requires\n",
    "𝐾\n",
    "K model trainings, where\n",
    "𝐾\n",
    "K is the number of folds.\n",
    "Bootstrapping: Typically requires more computational power as it involves training the model\n",
    "𝐵\n",
    "B times, where\n",
    "𝐵\n",
    "B (the number of bootstrap samples) is often larger than\n",
    "𝐾\n",
    "K.\n",
    "Summary\n",
    "MSE with K-Fold Cross-Validation is a reliable method for assessing model performance by ensuring that every data point is used both for training and validation.\n",
    "EMSE with Bootstrapping provides a more robust and generalized estimate by simulating the effect of drawing different datasets from the population, making it particularly useful when you need to understand the model’s performance in a broader context.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
